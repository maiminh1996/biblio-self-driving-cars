<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>biblio-self-driving-cars</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="biblio-self-driving-cars" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/dataset/cityscapes.html" />
<meta property="og:url" content="http://localhost:4000/dataset/cityscapes.html" />
<meta property="og:site_name" content="biblio-self-driving-cars" />
<script type="application/ld+json">
{"@type":"WebPage","url":"http://localhost:4000/dataset/cityscapes.html","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://maiminh1996.github.io/minh.png"}},"headline":"biblio-self-driving-cars","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=d118785de92220cec3651bfa4d7040244df72ae2">
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="http://localhost:4000/">biblio-self-driving-cars</a></h1>
        
        
          <img src="https://maiminh1996.github.io/minh.png" alt="Logo" />
        

        <p></p>

        
        <p class="view"><a href="https://github.com/maiminh1996/biblio-self-driving-cars">View the Project on GitHub <small>maiminh1996/biblio-self-driving-cars</small></a></p>
        

        

        
      </header>
      <section>

      <!-- CSS -->
<link rel="stylesheet" style="text/css" href="../styles.css" />

<!--     -->

<h2 id="cityscapes-">Cityscapes <img src="../doc/25.png" width="95" /></h2>
<h3 id="cvpr-16-the-cityscapes-dataset-for-semantic-urban-scene-understanding"><a href="https://www.cityscapes-dataset.com/wordpress/wp-content/papercite-data/pdf/cordts2016cityscapes.pdf"><kbd>CVPR 16</kbd> The Cityscapes Dataset for Semantic Urban Scene Understanding</a></h3>
<h3 id="cvpr-workshop-15-the-cityscapes-dataset"><a href="https://www.cityscapes-dataset.com/wordpress/wp-content/papercite-data/pdf/cordts2015cvprw.pdf"><kbd>CVPR Workshop 15</kbd> The Cityscapes Dataset</a></h3>

<p><a href="https://www.cityscapes-dataset.com/citation/">Link to web project</a></p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Category</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Overall impression</td>
      <td>mainly focuses on semantic segmentation tasks</td>
    </tr>
    <tr>
      <td style="text-align: center">Inputs</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Scenes</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Condition</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Tasks</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Gth</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Evaluation</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">Notes</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>The Cityscapes dataset [42] mainly focuses onsemantic segmentation tasks [37]. There are 5,000 images withfine  annotations  and  20,000  images  with  coarse  annotationsin  this  dataset.  Meanwhile,  this  dataset  consists  of  a  set  ofstereo video sequences, which are collected from 50 cities forseveral months. Since this dataset does not contain the groundtruth  of  depth,  it  is  only  applied  to  the  training  process  ofseveral unsupervised depth estimation methods [13], [15]. Theperformance of depth networks is improved by pre-training thenetworks on the Cityscapes, and the experiments in [43], [15],[13],  [44]  have  proved  the  effectiveness  of  this  joint  trainingmethod. The training data consists of 22,973 stereo image pairswith a resolution of 1024×2048 collected from different cities</p>


      </section>
      <footer>
        
        <p>This project is maintained by <a href="https://github.com/maiminh1996">maiminh1996</a></p>
        
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
    
  </body>
</html>
