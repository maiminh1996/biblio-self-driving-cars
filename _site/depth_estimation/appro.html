<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>biblio-self-driving-cars</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="biblio-self-driving-cars" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/depth_estimation/appro.html" />
<meta property="og:url" content="http://localhost:4000/depth_estimation/appro.html" />
<meta property="og:site_name" content="biblio-self-driving-cars" />
<script type="application/ld+json">
{"@type":"WebPage","url":"http://localhost:4000/depth_estimation/appro.html","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://maiminh1996.github.io/minh.png"}},"headline":"biblio-self-driving-cars","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=d118785de92220cec3651bfa4d7040244df72ae2">
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="http://localhost:4000/">biblio-self-driving-cars</a></h1>
        
        
          <img src="https://maiminh1996.github.io/minh.png" alt="Logo" />
        

        <p></p>

        
        <p class="view"><a href="https://github.com/maiminh1996/biblio-self-driving-cars">View the Project on GitHub <small>maiminh1996/biblio-self-driving-cars</small></a></p>
        

        

        
      </header>
      <section>

      <!-- CSS -->
<link rel="stylesheet" style="text/css" href="../styles.css" />

<!--     -->

<h2 id="depth-estimation-approaches">Depth Estimation/ Approaches</h2>

<ul>
  <li><a href="#monocular">Monocular (depth prediction)</a></li>
  <li><a href="#binocular">Binocular (depth prediction)</a></li>
  <li><a href="#depth-completion">Depth completion</a></li>
</ul>

<blockquote>
  <p><strong><em>Type 1:</em></strong> monocular (M), stereo (S), LiDAR (L), RADAR (R)<br /> 
<strong><em>Type 2:</em></strong> supervised (sup), unsupervised (unsup), semi-supervised, (semi-sup), self-supervised (self-sup)</p>
</blockquote>

<p>Other sources:</p>
<ul>
  <li><a href="https://medium.com/swlh/making-a-pseudo-lidar-with-cameras-and-deep-learning-e8f03f939c5f">Making a Pseudo LiDAR With Cameras and Deep Learning</a></li>
  <li><a href="https://medium.com/analytics-vidhya/depth-sensing-and-3d-reconstruction-512ed121aa60">extract the colors from the image to add to the pcl: XYZRGB –&gt; Meshlab</a></li>
</ul>

<details>
  <summary>General notes!</summary>

- Ref:  <a href="https://medium.com/swlh/making-a-pseudo-lidar-with-cameras-and-deep-learning-e8f03f939c5f">Depth normalization</a><br /> we need to penalize the things that are ‘closer’ more than the things that are far away, because for planning, closer objects would matter more mostly. --&gt; <b>Depth normalization </b> is the idea taking the inverse of the depth-map<br />
depthNormalized = maxDepth / original_depth_map<br />;where maxDepth is the max depth value in the whole dataset

</details>

<p>https://github.com/alexklwong/awesome-state-of-depth-completion</p>

<h2 id="monocular">Monocular</h2>

<h4 id="supervised">Supervised</h4>

<p><a href="https://arxiv.org/pdf/1406.2283.pdf"><kbd>NIPS 14</kbd> Eigen et al</a></p>

<p><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Fu_Deep_Ordinal_Regression_CVPR_2018_paper.pdf"><kbd>CVPR 18</kbd> DORN</a> (Discretized depth bins &gt; direct regression; binary classification 80 bins (Pixels with distance&gt;80m)) <a href="https://github.com/patrick-llgc/Learning-Deep-Learning/blob/master/paper_notes/dorn.md">[Notes]</a></p>

<h4 id="unsupervised">Unsupervised</h4>

<h4 id="semi-supervised">Semi-supervised</h4>

<h4 id="self-supervised">Self-supervised</h4>

<p><a href="https://proceedings.neurips.cc/paper/2020/file/951124d4a093eeae83d9726a20295498-Paper.pdf"><kbd>NIPS 20</kbd> FAL</a> (Occlusion-free reconstruction loss)</p>

<h2 id="binocular">Binocular</h2>

<h4 id="supervised-1">Supervised</h4>

<p><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Chang_Pyramid_Stereo_Matching_CVPR_2018_paper.pdf"><kbd>CVPR 18</kbd> PSMNet</a> () [<a href="/depth_estimation/psmnet.html">Notes</a>]</p>

<h4 id="unsupervised-1">Unsupervised</h4>

<h4 id="semi-supervised-1">Semi-supervised</h4>

<h4 id="self-supervised-1">Self-supervised</h4>

<h2 id="depth-completion">Depth completion</h2>

<h4 id="supervised-2">Supervised</h4>

<p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwifkZCW6oDuAhWMURUIHTqwCtYQFjACegQIAxAC&amp;url=http%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_CVPR_2019%2Fpapers%2FQiu_DeepLiDAR_Deep_Surface_Normal_Guided_Depth_Prediction_for_Outdoor_Scene_CVPR_2019_paper.pdf&amp;usg=AOvVaw1bPN7MFbPOOt4Bf7yynGPu"><kbd>CVPR 19</kbd> DeepLiDAR</a> () [<a href="deeplidar.md">Notes</a>]</p>

<h4 id="unsupervised-2">Unsupervised</h4>

<h4 id="semi-supervised-2">Semi-supervised</h4>

<h4 id="self-supervised-2">Self-supervised</h4>



      </section>
      <footer>
        
        <p>This project is maintained by <a href="https://github.com/maiminh1996">maiminh1996</a></p>
        
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
    
  </body>
</html>
