<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>biblio-self-driving-cars</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="biblio-self-driving-cars" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/network_problem.html" />
<meta property="og:url" content="http://localhost:4000/network_problem.html" />
<meta property="og:site_name" content="biblio-self-driving-cars" />
<script type="application/ld+json">
{"@type":"WebPage","url":"http://localhost:4000/network_problem.html","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://maiminh1996.github.io/minh.png"}},"headline":"biblio-self-driving-cars","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=e8f795b6dadcc381d57ecd565d6b297a714a47a7">
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="http://localhost:4000/">biblio-self-driving-cars</a></h1>
        
        
          <img src="https://maiminh1996.github.io/minh.png" alt="Logo" />
        

        <p></p>

        
        <p class="view"><a href="https://github.com/maiminh1996/biblio-self-driving-cars">View the Project on GitHub <small>maiminh1996/biblio-self-driving-cars</small></a></p>
        

        

        
      </header>
      <section>

      <!-- CSS -->
<link rel="stylesheet" style="text/css" href="../styles.css" />

<!--     -->

<h2 id="network-design">Network design</h2>

<table>
  <thead>
    <tr>
      <th>Net prob</th>
      <th>Ref</th>
      <th>Des</th>
      <th>Formula</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Resolution (multi-scale)</td>
      <td>Depth Map Prediction from a Single Imageusing a Multi-Scale Deep Network <br />FPN feature pyramid network <br />Fine-Grained Dynamic Head for Object Detection<br /></td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>attack adversarial</td>
      <td><a href="https://proceedings.neurips.cc/paper/2020/file/0dd1bc593a91620daecf7723d2235624-Paper.pdf"> Certified Object Detection</a></td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>Dense object detection</td>
      <td> </td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h2 id="lidar-in-neural-net">LiDAR in neural net</h2>
<p>| category | des |
| – | – |
| bird eye view (BEV) | PIXOR [4], based on 2D CNNs project point clouds into BEV. However, projection suffers from3D structural information loss <br /> To mitigate information loss, recent voxel-based detectors, such asVoxelNet [1], SECOND [2], PartA2[7] and Fast Point R-CNN [8], preserve the 3D structure duringvoxelization and adopt 3D CNNs at early or intermediate stages and finally project features to BEVand detect objects from BEV.|
| range view (RV) | There are very few works (LaserNet [5]) that learn representations fromRV. RV is a compact representation that aligns with LiDAR scan pattern. But current RV detectorsrequires more data to perform well [5] and are outperformed BEV detectors on public datasets [15]. <strong>Occlusion and different scales of objects</strong> in RV also pose challenges to detection. |
| Voxelization for pcl | To transform point clouds into image-like grid structures so that convolutional neural networks can beapplied, several works group point clouds into volumetric grids. Commonly used volumetric grids arecuboid-shaped ones under Cartesian coordinate system. VoxNet [10] represents the cuboid-shapedvoxels as occupancy grids: if there are no points in that voxel, the grid value is0, or1otherwise. Toavoid quantization effects of occupancy grids and extract richer voxel features, VoxelNet [1] samplesa fix number of points within each voxel and applies Voxel Feature Extractor (VFE, a small PointNet[11] made of fully connected layers and a max pooling layer) to points in each voxel to extract voxelfeatures. For efficiency, PointPillars [3] discretizes the 3D space into pillars so there is only one voxelalong the height dimension.Some recent works start to explore voxel shapes other than cuboids. Alsfasser et al [12] voxelizespoints under the Cylindrical Coordinate System. PolarNet [13] groups points into 2D polar grids onBEV for semantic segmentation. MVF [14] adopts both cuboid-shape voxels and spherical voxels. <br /> <img src="/doc/voxel_method.png" alt="" /> |</p>

<h3 id="general-notes">General notes</h3>
<ul>
  <li>Need to leverage these encoders like ResNet, DenseNet, etc which are pre-trained on ImageNet dataset</li>
  <li>decoder part uses Bilinear Upsampling (brief: a ‘smoother’ image overall after upsampling) rather than simple Upsampling</li>
</ul>


      </section>
      <footer>
        
        <p>This project is maintained by <a href="https://github.com/maiminh1996">maiminh1996</a></p>
        
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
    
  </body>
</html>
